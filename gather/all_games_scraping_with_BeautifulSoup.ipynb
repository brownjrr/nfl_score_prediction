{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap NFL Games Data From PFR\n",
    "Scrap NFL game data for year(s) from https://www.pro-football-reference.com with sleep time between 3.5 to 5.5 seconds to avoid overwhelming the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## weather func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_weather(weather_text):\n",
    "    \"\"\"\n",
    "    Parse the weather information to extract temperature, humidity, and wind speed.\n",
    "\n",
    "    Parameters:\n",
    "    weather_text (str): Text containing weather information in a specific format.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing temperature (float), humidity_pct (float), and wind_speed (float).\n",
    "    \"\"\"\n",
    "    temperature = None\n",
    "    humidity_pct = None\n",
    "    wind_speed = None\n",
    "\n",
    "    parts = weather_text.split(\", \")\n",
    "    for part in parts:\n",
    "        if 'degrees' in part:\n",
    "            temperature = float(part.split()[0])\n",
    "        if 'humidity' in part:\n",
    "            humidity_pct = float(part.split()[2].replace('%', ''))\n",
    "        if 'mph' in part:\n",
    "            wind_speed = float(part.split()[1])\n",
    "    \n",
    "    return temperature, humidity_pct, wind_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_func(url):\n",
    "    \"\"\"\n",
    "    Extract the date from the given URL.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL containing date information.\n",
    "\n",
    "    Returns:\n",
    "    str: Formatted event date in 'YYYY-MM-DD' format.\n",
    "    \"\"\"\n",
    "    event_date = f'{url[-16:-12]}-{url[-12:-10]}-{url[-10:-8]}'\n",
    "    return event_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## games starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_starters(comments,event_date):\n",
    "    \"\"\"\n",
    "    Extract starting players' data for each team from comments.\n",
    "\n",
    "    Parameters:\n",
    "    comments (list): List of comments containing HTML tables of starters.\n",
    "    event_date (str): Date of the event in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing starting player details including player ID, name, position, and team.\n",
    "    \"\"\"\n",
    "    table_data = [] \n",
    "\n",
    "    # Iterate over each comment and parse the one that contains 'home_starters' or 'vis_starters'\n",
    "    for comment in comments:\n",
    "        if 'id=\"home_starters\"' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            table = comment_soup.find('table')\n",
    "            \n",
    "            if table:\n",
    "                # Extract the team name from the caption dynamically\n",
    "                team_name = table.find('caption').get_text().split(' Starters Table')[0]\n",
    "                rows = table.find_all('tr')[1:]  # Skip header row\n",
    "\n",
    "                # Loop through each row and extract player data\n",
    "                for row in rows:\n",
    "                    player_tag = row.find('th', {'data-stat': 'player'})\n",
    "                    if player_tag:\n",
    "                        player_id = player_tag['data-append-csv']\n",
    "                        player_name = player_tag.find('a').get_text()\n",
    "                        position = row.find('td', {'data-stat': 'pos'}).get_text()\n",
    "                        home = 1\n",
    "                        date = event_date\n",
    "                        table_data.append([date, team_name, player_id, player_name, position, home])\n",
    "        elif 'id=\"vis_starters\"' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            table = comment_soup.find('table')\n",
    "            \n",
    "            if table:\n",
    "                # Extract the team name from the caption dynamically\n",
    "                team_name = table.find('caption').get_text().split(' Starters Table')[0]\n",
    "                rows = table.find_all('tr')[1:]  # Skip header row\n",
    "\n",
    "                # Loop through each row and extract player data\n",
    "                for row in rows:\n",
    "                    player_tag = row.find('th', {'data-stat': 'player'})\n",
    "                    if player_tag:\n",
    "                        player_id = player_tag['data-append-csv']\n",
    "                        player_name = player_tag.find('a').get_text()\n",
    "                        position = row.find('td', {'data-stat': 'pos'}).get_text()\n",
    "                        home = 0\n",
    "                        date = event_date\n",
    "                        table_data.append([date, team_name, player_id, player_name, position, home])\n",
    "\n",
    "    # Convert the list to a DataFrame\n",
    "    df = pd.DataFrame(table_data, columns=[\"Date\",\"Team\", \"Player_id\", \"Starter\", \"Position\", \"Home\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# snap counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def snap_counts(comments,event_date):\n",
    "    \"\"\"\n",
    "    Extract snap count data for each player from comments.\n",
    "\n",
    "    Parameters:\n",
    "    comments (list): List of comments containing HTML tables of snap counts.\n",
    "    event_date (str): Date of the event in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing snap counts for players including offensive, defensive, and special teams data.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store table data\n",
    "    snap_data = [] \n",
    "\n",
    "    # Iterate over each comment and parse the one that contains 'home_starters' or 'vis_starters'\n",
    "    for comment in comments:\n",
    "        if 'id=\"home_snap_counts\"' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            table = comment_soup.find('table')\n",
    "            \n",
    "            if table:\n",
    "                # Extract the team name from the caption dynamically\n",
    "                team_name = table.find('caption').get_text().split(' Snap Counts Table')[0]\n",
    "                rows = table.find_all('tr')[2:]  # Skip header row\n",
    "\n",
    "                for row in rows:\n",
    "                    # Extract each field (skip rows without enough columns)\n",
    "                    columns = row.find_all('td')\n",
    "\n",
    "                    # extract player data\n",
    "                    player_tag = row.find('th', {'data-stat': 'player'})\n",
    "                    if player_tag:\n",
    "                        player_id = player_tag['data-append-csv']\n",
    "                        player_name = player_tag.find('a').get_text()\n",
    "\n",
    "                    # Extract required data\n",
    "                    pos = columns[0].text.strip()\n",
    "                    off_num = columns[1].text.strip()\n",
    "                    off_pct = columns[2].text.strip()\n",
    "                    def_num = columns[3].text.strip()\n",
    "                    def_pct = columns[4].text.strip()\n",
    "                    st_num = columns[5].text.strip()\n",
    "                    st_pct = columns[6].text.strip()\n",
    "                    date = event_date\n",
    "                    snap_data.append([date, team_name, player_id, player_name, pos, off_num, off_pct, def_num, def_pct, st_num, st_pct])\n",
    "                    \n",
    "        if 'id=\"vis_snap_counts\"' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            table = comment_soup.find('table')\n",
    "            \n",
    "            if table:\n",
    "                # Extract the team name from the caption dynamically\n",
    "                team_name = table.find('caption').get_text().split(' Snap Counts Table')[0]\n",
    "                rows = table.find_all('tr')[2:]  # Skip header row\n",
    "\n",
    "                for row in rows:\n",
    "                    # Extract each field (skip rows without enough columns)\n",
    "                    columns = row.find_all('td')\n",
    "\n",
    "                    # extract player data\n",
    "                    player_tag = row.find('th', {'data-stat': 'player'})\n",
    "                    if player_tag:\n",
    "                        player_id = player_tag['data-append-csv']\n",
    "                        player_name = player_tag.find('a').get_text()\n",
    "\n",
    "                    # Extract required data\n",
    "                    pos = columns[0].text.strip()\n",
    "                    off_num = columns[1].text.strip()\n",
    "                    off_pct = columns[2].text.strip()\n",
    "                    def_num = columns[3].text.strip()\n",
    "                    def_pct = columns[4].text.strip()\n",
    "                    st_num = columns[5].text.strip()\n",
    "                    st_pct = columns[6].text.strip()\n",
    "                    date = event_date\n",
    "                    snap_data.append([date, team_name, player_id, player_name, pos, off_num, off_pct, def_num, def_pct, st_num, st_pct])\n",
    "\n",
    "    # Convert the list to a DataFrame\n",
    "    df = pd.DataFrame(snap_data, columns=[\"date\",\"team\", \"player_id\", \"player\", \"position\", \"off_num\",\"off_pct\",\"def_num\",\"def_pct\",\"st_num\",\"st_pct\"])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing, Rushing, & Receiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_offense(soup,event_date):\n",
    "    \"\"\"\n",
    "    Extract offensive player stats from the HTML soup.\n",
    "\n",
    "    Parameters:\n",
    "    soup (BeautifulSoup): Parsed HTML content of the page.\n",
    "    event_date (str): Date of the event in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing offensive player statistics such as passing, rushing, and receiving.\n",
    "    \"\"\"\n",
    "    # Find the table by ID\n",
    "    table = soup.find('table', id='player_offense')\n",
    "\n",
    "    # Initialize a list to hold player data\n",
    "    offense_data = []\n",
    "\n",
    "    # Loop through the rows in the table body\n",
    "    for row in table.find('tbody').find_all('tr'):\n",
    "        # Create a dictionary to store the player's stats\n",
    "        player_stats = {}\n",
    "        \n",
    "        data_tag = row.find_all('td')\n",
    "        if not data_tag:\n",
    "            # Skip rows that have fewer columns (short rows)\n",
    "            continue\n",
    "        # Extract the player's name\n",
    "        try:\n",
    "            player_tag = row.find('th', {'data-stat': 'player'})\n",
    "            if player_tag:\n",
    "                player_id = player_tag['data-append-csv']\n",
    "                player_name = player_tag.find('a').get_text()\n",
    "\n",
    "            team = data_tag[0].text.strip()\n",
    "            pass_cmp = data_tag[1].text.strip()\n",
    "            pass_att = data_tag[2].text.strip()\n",
    "            pass_yds = data_tag[3].text.strip()\n",
    "            pass_td = data_tag[4].text.strip()\n",
    "            pass_int = data_tag[5].text.strip()\n",
    "            pass_sacked = data_tag[6].text.strip()\n",
    "            pass_sacked_yds = data_tag[7].text.strip()\n",
    "            pass_long = data_tag[8].text.strip()\n",
    "            pass_rating = data_tag[9].text.strip()\n",
    "            rush_att = data_tag[10].text.strip()\n",
    "            rush_yds = data_tag[11].text.strip()\n",
    "            rush_td = data_tag[12].text.strip()\n",
    "            rush_long = data_tag[13].text.strip()\n",
    "            rec_tgt = data_tag[14].text.strip()\n",
    "            rec_rec = data_tag[15].text.strip()\n",
    "            rec_yds = data_tag[16].text.strip()\n",
    "            rec_td = data_tag[17].text.strip()\n",
    "            rec_long = data_tag[18].text.strip()\n",
    "            fmb = data_tag[19].text.strip()\n",
    "            fmb_lost = data_tag[20].text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        clmn = [event_date,player_id,player_name,team,pass_cmp,pass_att,pass_yds,pass_td,pass_int,pass_sacked,pass_sacked_yds,pass_long,pass_rating,\n",
    "                rush_att,rush_yds,rush_td,rush_long,rec_tgt,rec_rec,rec_yds,rec_td,rec_long,fmb,fmb_lost]\n",
    "        offense_data.append(clmn)\n",
    "    df = pd.DataFrame(offense_data,columns=['date','player_id', 'player_name', 'team', 'pass_cmp', 'pass_att', 'pass_yds', 'pass_td', 'pass_int', 'pass_sacked', 'pass_sacked_yds',\n",
    "    'pass_long', 'pass_rating', 'rush_att', 'rush_yds', 'rush_td', 'rush_long', 'rec_tgt', 'rec_rec', 'rec_yds', 'rec_td', \n",
    "    'rec_long', 'fmb', 'fmb_lost'])\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_defense(comments,event_date):\n",
    "    \"\"\"\n",
    "    Extract defensive player stats from comments.\n",
    "\n",
    "    Parameters:\n",
    "    comments (list): List of comments containing HTML tables of player defense stats.\n",
    "    event_date (str): Date of the event in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing defensive player statistics such as tackles, sacks, interceptions.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store table data\n",
    "    diff_data = [] \n",
    "\n",
    "    # Iterate over each comment and parse the one that contains 'home_starters' or 'vis_starters'\n",
    "    for comment in comments:\n",
    "        if 'id=\"player_defense\"' in comment:\n",
    "                comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "                table = comment_soup.find('table')\n",
    "\n",
    "                if table:\n",
    "                    # Extract the team name from the caption dynamically\n",
    "                    rows = table.find_all('tr')[2:]  # Skip header row\n",
    "                    # Extract each field (skip rows without enough columns)\n",
    "                    for row in rows:\n",
    "                        data_tag = row.find_all('td')\n",
    "                        if not data_tag:\n",
    "                            # Skip rows that have fewer columns (short rows)\n",
    "                            continue\n",
    "    \n",
    "                        # extract player data\n",
    "                        player_tag = row.find('th', {'data-stat': 'player'})\n",
    "                        if player_tag:\n",
    "                            player_id = player_tag['data-append-csv']\n",
    "                            player_name = player_tag.find('a').get_text()\n",
    "                        team = data_tag[0].text.strip()\n",
    "                        def_int = data_tag[1].text.strip()\n",
    "                        def_int_yds = data_tag[2].text.strip()\n",
    "                        def_int_td = data_tag[3].text.strip()\n",
    "                        def_int_long = data_tag[4].text.strip()\n",
    "                        pass_defended = data_tag[5].text.strip()\n",
    "                        sacks = data_tag[6].text.strip()\n",
    "                        tackles_combined = data_tag[7].text.strip()\n",
    "                        tackles_solo = data_tag[8].text.strip()\n",
    "                        tackles_assists = data_tag[9].text.strip()\n",
    "                        tackles_loss = data_tag[10].text.strip()\n",
    "                        qb_hits = data_tag[11].text.strip()\n",
    "                        fumbles_rec = data_tag[12].text.strip()\n",
    "                        fumbles_rec_yds = data_tag[13].text.strip()\n",
    "                        fumbles_rec_td = data_tag[14].text.strip()\n",
    "                        fumbles_forced = data_tag[15].text.strip()\n",
    "                        diff_data.append([event_date,player_id, player_name, team,def_int,def_int_yds,def_int_td,def_int_long,pass_defended,sacks,tackles_combined,tackles_solo,\n",
    "                                    tackles_assists,tackles_loss,qb_hits,fumbles_rec,fumbles_rec_yds,fumbles_rec_td,fumbles_forced])\n",
    "                    \n",
    "    df = pd.DataFrame(diff_data,columns=['date','player_id','player','team', 'def_int', 'def_int_yds', 'def_int_td', 'def_int_long', 'pass_defended', 'sacks', 'tackles_combined', 'tackles_solo',\n",
    "                                                    'tackles_assists', 'tackles_loss', 'qb_hits', 'fumbles_rec', 'fumbles_rec_yds', 'fumbles_rec_td', 'fumbles_forced'])\n",
    "    return df             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_returns(comments,event_date):\n",
    "    \"\"\"\n",
    "    Extract return player stats from comments.\n",
    "\n",
    "    Parameters:\n",
    "    comments (list): List of comments containing HTML tables of player return stats.\n",
    "    event_date (str): Date of the event in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing player return statistics such as kick and punt returns.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store table data\n",
    "    returns_data = [] \n",
    "\n",
    "    # Iterate over each comment and parse the one that contains 'home_starters' or 'vis_starters'\n",
    "    for comment in comments:\n",
    "        if 'id=\"returns\"' in comment:\n",
    "                comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "                table = comment_soup.find('table')\n",
    "\n",
    "                if table:\n",
    "                    # Extract the team name from the caption dynamically\n",
    "                    rows = table.find_all('tr')[2:]  # Skip header row\n",
    "                    # Extract each field (skip rows without enough columns)\n",
    "                    for row in rows:\n",
    "                        data_tag = row.find_all('td')\n",
    "                        if not data_tag:\n",
    "                            # Skip rows that have fewer columns (short rows)\n",
    "                            continue\n",
    "\n",
    "                        # extract player data\n",
    "                        player_tag = row.find('th', {'data-stat': 'player'})\n",
    "                        if player_tag:\n",
    "                            player_id = player_tag['data-append-csv']\n",
    "                            player_name = player_tag.find('a').get_text()\n",
    "                        team = data_tag[0].text.strip() \n",
    "                        kick_ret = data_tag[1].text.strip()\n",
    "                        kick_ret_yds = data_tag[2].text.strip() \n",
    "                        kick_ret_yds_per_ret = data_tag[3].text.strip() \n",
    "                        kick_ret_td = data_tag[4].text.strip()\n",
    "                        kick_ret_long = data_tag[5].text.strip()\n",
    "                        punt_ret = data_tag[6].text.strip()\n",
    "                        punt_ret_yds = data_tag[7].text.strip()\n",
    "                        punt_ret_yds_per_ret = data_tag[8].text.strip() \n",
    "                        punt_ret_td = data_tag[9].text.strip()\n",
    "                        punt_ret_long= data_tag[10].text.strip()\n",
    "                        returns_data.append([event_date,player_id,player_name,team,kick_ret,kick_ret_yds,kick_ret_yds_per_ret,kick_ret_td,kick_ret_long,\n",
    "                                            punt_ret,punt_ret_yds,punt_ret_yds_per_ret,punt_ret_td,punt_ret_long])\n",
    "    df = pd.DataFrame(returns_data,columns=['date','player_id', 'player_name', 'team', 'kick_ret', 'kick_ret_yds', 'kick_ret_yds_per_ret', \n",
    "                                                    'kick_ret_td', 'kick_ret_long','punt_ret', 'punt_ret_yds', 'punt_ret_yds_per_ret', 'punt_ret_td', 'punt_ret_long'])\n",
    "    return  df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kicking and Punting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_kicking(comments,event_date):\n",
    "    \"\"\"\n",
    "    Extract kicking player stats from comments.\n",
    "\n",
    "    Parameters:\n",
    "    comments (list): List of comments containing HTML tables of player kicking stats.\n",
    "    event_date (str): Date of the event in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing player kicking statistics such as field goals, punts, and extra points.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store table data\n",
    "    kicking_data = [] \n",
    "\n",
    "    # Iterate over each comment and parse the one that contains 'home_starters' or 'vis_starters'\n",
    "    for comment in comments:\n",
    "        if 'id=\"kicking\"' in comment:\n",
    "                comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "                table = comment_soup.find('table')\n",
    "\n",
    "                if table:\n",
    "                    # Extract the team name from the caption dynamically\n",
    "                    rows = table.find_all('tr')[2:]  # Skip header row\n",
    "                    # Extract each field (skip rows without enough columns)\n",
    "                    for row in rows:\n",
    "                        data_tag = row.find_all('td')\n",
    "                        if not data_tag:\n",
    "                            # Skip rows that have fewer columns (short rows)\n",
    "                            continue\n",
    "                        # extract player data\n",
    "                        player_tag = row.find('th', {'data-stat': 'player'})\n",
    "                        if player_tag:\n",
    "                            player_id = player_tag['data-append-csv']\n",
    "                            player_name = player_tag.find('a').get_text()\n",
    "\n",
    "                        team = data_tag[0].text.strip() \n",
    "                        scoring_xpm = data_tag[1].text.strip()\n",
    "                        scoring_xpa = data_tag[2].text.strip() \n",
    "                        scoring_fgm = data_tag[3].text.strip() \n",
    "                        scoring_fga = data_tag[4].text.strip()\n",
    "                        punt = data_tag[5].text.strip()\n",
    "                        punt_yds = data_tag[6].text.strip()\n",
    "                        punt_yds_per_punt = data_tag[7].text.strip()\n",
    "                        punt_long = data_tag[8].text.strip() \n",
    "                        kicking_data.append([event_date,player_id, player_name, team,scoring_xpm,scoring_xpa,scoring_fgm,scoring_fga,punt,punt_yds,punt_yds_per_punt,punt_long])\n",
    "    df = pd.DataFrame(kicking_data,columns=['date','player_id', 'player_name', 'team', 'scoring_xpm', 'scoring_xpa', 'scoring_fgm', 'scoring_fga',\n",
    "                                                        'punt', 'punt_yds', 'punt_yds_per_punt', 'punt_long'])\n",
    "    return df\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_advanced_passing(comments,event_date):\n",
    "    \"\"\"\n",
    "    Extract advanced passing stats for players from comments.\n",
    "\n",
    "    Parameters:\n",
    "    comments (list): List of comments containing HTML tables of advanced passing stats.\n",
    "    event_date (str): Date of the event in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing advanced passing statistics such as air yards, yards after catch.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store table data\n",
    "    advanced_passing_data = [] \n",
    "\n",
    "    # Iterate over each comment and parse the one that contains 'home_starters' or 'vis_starters'\n",
    "    for comment in comments:\n",
    "        if 'id=\"passing_advanced\"' in comment:\n",
    "                comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "                table = comment_soup.find('table')\n",
    "\n",
    "                if table:\n",
    "                    # Extract the team name from the caption dynamically\n",
    "                    rows = table.find_all('tr')[1:]  # Skip header row\n",
    "                    # Extract each field (skip rows without enough columns)\n",
    "                    for row in rows:\n",
    "                        data_tag = row.find_all('td')\n",
    "                        if not data_tag:\n",
    "                            # Skip rows that have fewer columns (short rows)\n",
    "                            continue\n",
    "                        # extract player data\n",
    "                        player_tag = row.find('th', {'data-stat': 'player'})\n",
    "                        if player_tag:\n",
    "                            player_id = player_tag['data-append-csv']\n",
    "                            player_name = player_tag.find('a').get_text()\n",
    "                        team = data_tag[0].text.strip()\n",
    "                        pass_cmp = data_tag[1].text.strip()\n",
    "                        pass_att = data_tag[2].text.strip()\n",
    "                        pass_yds = data_tag[3].text.strip()\n",
    "                        pass_first_down = data_tag[4].text.strip()\n",
    "                        pass_first_down_pct = data_tag[5].text.strip()\n",
    "                        pass_target_yds = data_tag[6].text.strip()\n",
    "                        pass_tgt_yds_per_att = data_tag[7].text.strip()\n",
    "                        pass_air_yds = data_tag[8].text.strip()\n",
    "                        pass_air_yds_per_cmp = data_tag[9].text.strip()\n",
    "                        pass_air_yds_per_att = data_tag[10].text.strip()\n",
    "                        pass_yac = data_tag[11].text.strip()\n",
    "                        pass_yac_per_cmp = data_tag[12].text.strip()\n",
    "                        pass_drops = data_tag[13].text.strip()\n",
    "                        pass_drop_pct = data_tag[14].text.strip()\n",
    "                        pass_poor_throws = data_tag[15].text.strip()\n",
    "                        pass_poor_throw_pct = data_tag[16].text.strip()\n",
    "                        pass_sacked = data_tag[17].text.strip()\n",
    "                        pass_blitzed = data_tag[18].text.strip()\n",
    "                        pass_hurried = data_tag[19].text.strip()\n",
    "                        pass_hits = data_tag[20].text.strip()\n",
    "                        pass_pressured = data_tag[21].text.strip()\n",
    "                        pass_pressured_pct = data_tag[22].text.strip()\n",
    "                        rush_scrambles = data_tag[23].text.strip()\n",
    "                        rush_scrambles_yds_per_att = data_tag[24].text.strip()\n",
    "\n",
    "                        # Append the extracted stats to the player_stats_list\n",
    "                        advanced_passing_data.append([event_date,player_id, player_name, team, pass_cmp, pass_att, pass_yds, pass_first_down, pass_first_down_pct, pass_target_yds, \n",
    "                                                pass_tgt_yds_per_att, pass_air_yds, pass_air_yds_per_cmp, pass_air_yds_per_att, pass_yac, \n",
    "                                                pass_yac_per_cmp, pass_drops, pass_drop_pct, pass_poor_throws, pass_poor_throw_pct, pass_sacked,\n",
    "                                                pass_blitzed, pass_hurried, pass_hits, pass_pressured, pass_pressured_pct, rush_scrambles, \n",
    "                                                rush_scrambles_yds_per_att])\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(advanced_passing_data, columns=[\n",
    "                        'date','player_id', 'player_name', 'team', 'pass_cmp', 'pass_att', 'pass_yds', 'pass_first_down', 'pass_first_down_pct', 'pass_target_yds', 'pass_tgt_yds_per_att', \n",
    "                        'pass_air_yds', 'pass_air_yds_per_cmp', 'pass_air_yds_per_att', 'pass_yac', 'pass_yac_per_cmp', 'pass_drops', 'pass_drop_pct',\n",
    "                        'pass_poor_throws', 'pass_poor_throw_pct', 'pass_sacked', 'pass_blitzed', 'pass_hurried', 'pass_hits', 'pass_pressured', \n",
    "                        'pass_pressured_pct', 'rush_scrambles', 'rush_scrambles_yds_per_att'])\n",
    "    return df\n",
    "                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Rushing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_advanced_rushing(comments,event_date):\n",
    "    \"\"\"\n",
    "    Extract advanced rushing stats for players from comments.\n",
    "\n",
    "    Parameters:\n",
    "    comments (list): List of comments containing HTML tables of advanced rushing stats.\n",
    "    event_date (str): Date of the event in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing advanced rushing statistics like yards before contact and yards after contact.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store table data\n",
    "    advanced_rushing_data = [] \n",
    "\n",
    "    # Iterate over each comment and parse the one that contains 'home_starters' or 'vis_starters'\n",
    "    for comment in comments:\n",
    "        if 'id=\"rushing_advanced\"' in comment:\n",
    "                comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "                table = comment_soup.find('table')\n",
    "\n",
    "                if table:\n",
    "                    # Extract the team name from the caption dynamically\n",
    "                    rows = table.find_all('tr')[1:]  # Skip header row\n",
    "                    # Extract each field (skip rows without enough columns)\n",
    "                    for row in rows:\n",
    "                        data_tag = row.find_all('td')\n",
    "                        if not data_tag:\n",
    "                            # Skip rows that have fewer columns (short rows)\n",
    "                            continue\n",
    "                        # extract player data\n",
    "                        player_tag = row.find('th', {'data-stat': 'player'})\n",
    "                        if player_tag:\n",
    "                            player_id = player_tag['data-append-csv']\n",
    "                            player_name = player_tag.find('a').get_text()\n",
    "                        team = data_tag[0].text.strip()\n",
    "                        rush_att = data_tag[1].text.strip()\n",
    "                        rush_yds = data_tag[2].text.strip()\n",
    "                        rush_td = data_tag[3].text.strip()\n",
    "                        rush_first_down = data_tag[4].text.strip()\n",
    "                        rush_yds_before_contact = data_tag[5].text.strip()\n",
    "                        rush_yds_bc_per_rush = data_tag[6].text.strip()\n",
    "                        rush_yac = data_tag[7].text.strip()\n",
    "                        rush_yac_per_rush = data_tag[8].text.strip()\n",
    "                        rush_broken_tackles = data_tag[9].text.strip()\n",
    "                        rush_broken_tackles_per_rush = data_tag[10].text.strip()\n",
    "\n",
    "                        # Append the extracted stats to the rushing_stats_list\n",
    "                        advanced_rushing_data.append([event_date,player_id, player_name, team, rush_att, rush_yds, rush_td, rush_first_down, rush_yds_before_contact, \n",
    "                                                rush_yds_bc_per_rush, rush_yac, rush_yac_per_rush, rush_broken_tackles, rush_broken_tackles_per_rush])\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(advanced_rushing_data, columns=[\n",
    "                        'date','player_id', 'player_name', 'team', 'rush_att', 'rush_yds', 'rush_td', 'rush_first_down', 'rush_yds_before_contact', \n",
    "                        'rush_yds_bc_per_rush', 'rush_yac', 'rush_yac_per_rush', 'rush_broken_tackles', 'rush_broken_tackles_per_rush'\n",
    "                    ])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Receiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_advanced_receiving(comments,event_date):\n",
    "    \"\"\"\n",
    "    Extract advanced receiving stats for players from comments.\n",
    "\n",
    "    Parameters:\n",
    "    comments (list): List of comments containing HTML tables of advanced receiving stats.\n",
    "    event_date (str): Date of the event in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing advanced receiving statistics such as air yards, yards after catch, and drop rates.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store table data\n",
    "    advanced_receiving_data = [] \n",
    "\n",
    "    # Iterate over each comment and parse the one that contains 'home_starters' or 'vis_starters'\n",
    "    for comment in comments:\n",
    "        if 'id=\"receiving_advanced\"' in comment:\n",
    "                comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "                table = comment_soup.find('table')\n",
    "\n",
    "                if table:\n",
    "                    # Extract the team name from the caption dynamically\n",
    "                    rows = table.find_all('tr')[1:]  # Skip header row\n",
    "                    # Extract each field (skip rows without enough columns)\n",
    "                    for row in rows:\n",
    "                        data_tag = row.find_all('td')\n",
    "                        if not data_tag:\n",
    "                            # Skip rows that have fewer columns (short rows)\n",
    "                            continue\n",
    "                        # extract player data\n",
    "                        player_tag = row.find('th', {'data-stat': 'player'})\n",
    "                        if player_tag:\n",
    "                            player_id = player_tag['data-append-csv']\n",
    "                            player_name = player_tag.find('a').get_text()\n",
    "                        team = data_tag[0].text.strip()\n",
    "                        targets = data_tag[1].text.strip()\n",
    "                        rec = data_tag[2].text.strip()\n",
    "                        rec_yds = data_tag[3].text.strip()\n",
    "                        rec_td = data_tag[4].text.strip()\n",
    "                        rec_first_down = data_tag[5].text.strip()\n",
    "                        rec_air_yds = data_tag[6].text.strip()\n",
    "                        rec_air_yds_per_rec = data_tag[7].text.strip()\n",
    "                        rec_yac = data_tag[8].text.strip()\n",
    "                        rec_yac_per_rec = data_tag[9].text.strip()\n",
    "                        rec_adot = data_tag[10].text.strip()\n",
    "                        rec_broken_tackles = data_tag[11].text.strip()\n",
    "                        rec_broken_tackles_per_rec = data_tag[12].text.strip()\n",
    "                        rec_drops = data_tag[13].text.strip()\n",
    "                        rec_drop_pct = data_tag[14].text.strip()\n",
    "                        rec_target_int = data_tag[15].text.strip()\n",
    "                        rec_pass_rating = data_tag[16].text.strip()\n",
    "\n",
    "                        # Append the extracted stats to the receiving_stats_list\n",
    "                        advanced_receiving_data.append([event_date,player_id, player_name, team, targets, rec, rec_yds, rec_td, rec_first_down, rec_air_yds, \n",
    "                                                    rec_air_yds_per_rec, rec_yac, rec_yac_per_rec, rec_adot, rec_broken_tackles,\n",
    "                                                    rec_broken_tackles_per_rec, rec_drops, rec_drop_pct, rec_target_int, rec_pass_rating])\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(advanced_receiving_data, columns=[\n",
    "                        'date','player_id', 'player_name', 'team', 'targets', 'rec', 'rec_yds', 'rec_td', 'rec_first_down', 'rec_air_yds', 'rec_air_yds_per_rec', \n",
    "                        'rec_yac', 'rec_yac_per_rec', 'rec_adot', 'rec_broken_tackles', 'rec_broken_tackles_per_rec', 'rec_drops',\n",
    "                        'rec_drop_pct', 'rec_target_int', 'rec_pass_rating'\n",
    "                    ])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_advanced_defense(comments,event_date):\n",
    "    \"\"\"\n",
    "    Extract advanced defensive stats for players from comments.\n",
    "\n",
    "    Parameters:\n",
    "    comments (list): List of comments containing HTML tables of advanced defensive stats.\n",
    "    event_date (str): Date of the event in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing advanced defensive statistics such as pressures, missed tackles, and blitzes.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store table data\n",
    "    advanced_defense_data = [] \n",
    "\n",
    "    # Iterate over each comment and parse the one that contains 'home_starters' or 'vis_starters'\n",
    "    for comment in comments:\n",
    "        if 'id=\"defense_advanced\"' in comment:\n",
    "                comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "                table = comment_soup.find('table')\n",
    "\n",
    "                if table:\n",
    "                    # Extract the team name from the caption dynamically\n",
    "                    rows = table.find_all('tr')[1:]  # Skip header row\n",
    "                    # Extract each field (skip rows without enough columns)\n",
    "                    for row in rows:\n",
    "                        data_tag = row.find_all('td')\n",
    "                        if not data_tag:\n",
    "                            # Skip rows that have fewer columns (short rows)\n",
    "                            continue\n",
    "                        # extract player data\n",
    "                        player_tag = row.find('th', {'data-stat': 'player'})\n",
    "                        if player_tag:\n",
    "                            player_id = player_tag['data-append-csv']\n",
    "                            player_name = player_tag.find('a').get_text()\n",
    "                        team = data_tag[0].text.strip()\n",
    "                        def_int = data_tag[1].text.strip()\n",
    "                        def_targets = data_tag[2].text.strip()\n",
    "                        def_cmp = data_tag[3].text.strip()\n",
    "                        def_cmp_perc = data_tag[4].text.strip()\n",
    "                        def_cmp_yds = data_tag[5].text.strip()\n",
    "                        def_yds_per_cmp = data_tag[6].text.strip()\n",
    "                        def_yds_per_target = data_tag[7].text.strip()\n",
    "                        def_cmp_td = data_tag[8].text.strip()\n",
    "                        def_pass_rating = data_tag[9].text.strip()\n",
    "                        def_tgt_yds_per_att = data_tag[10].text.strip()\n",
    "                        def_air_yds = data_tag[11].text.strip()\n",
    "                        def_yac = data_tag[12].text.strip()\n",
    "                        blitzes = data_tag[13].text.strip()\n",
    "                        qb_hurry = data_tag[14].text.strip()\n",
    "                        qb_knockdown = data_tag[15].text.strip()\n",
    "                        sacks = data_tag[16].text.strip()\n",
    "                        pressures = data_tag[17].text.strip()\n",
    "                        tackles_combined = data_tag[18].text.strip()\n",
    "                        tackles_missed = data_tag[19].text.strip()\n",
    "                        tackles_missed_pct = data_tag[20].text.strip()\n",
    "\n",
    "                        # Append the extracted stats to the defensive_stats_list\n",
    "                        advanced_defense_data.append([event_date,player_id, player_name, team, def_int, def_targets, def_cmp, def_cmp_perc, def_cmp_yds, def_yds_per_cmp, \n",
    "                                                    def_yds_per_target, def_cmp_td, def_pass_rating, def_tgt_yds_per_att, def_air_yds, \n",
    "                                                    def_yac, blitzes, qb_hurry, qb_knockdown, sacks, pressures, tackles_combined, \n",
    "                                                    tackles_missed, tackles_missed_pct])\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(advanced_defense_data, columns=[\n",
    "                        'date','player_id', 'player_name', 'team', 'def_int', 'def_targets', 'def_cmp', 'def_cmp_perc', 'def_cmp_yds', 'def_yds_per_cmp', 'def_yds_per_target',\n",
    "                        'def_cmp_td', 'def_pass_rating', 'def_tgt_yds_per_att', 'def_air_yds', 'def_yac', 'blitzes', 'qb_hurry', 'qb_knockdown',\n",
    "                        'sacks', 'pressures', 'tackles_combined', 'tackles_missed', 'tackles_missed_pct'\n",
    "                    ])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## team stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_stats(comments,event_date):\n",
    "    \"\"\"\n",
    "    Extract team statistics from comments.\n",
    "\n",
    "    Parameters:\n",
    "    comments (list): List of comments containing HTML tables of team statistics.\n",
    "    event_date (str): Date of the event in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing team statistics such as rushing yards, passing yards, and turnovers.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store table data\n",
    "    data = []\n",
    "    for comment in comments:\n",
    "        if 'id=\"team_stats\"' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            table = comment_soup.find('table')\n",
    "            \n",
    "            # Extract rows from the table\n",
    "            rows = table.find_all('tr')\n",
    "            \n",
    "            # Extract the team names from the header\n",
    "            headers = table.find('thead').find_all('th')\n",
    "            visitor_team = headers[1].text.strip()\n",
    "            home_team = headers[2].text.strip()\n",
    "\n",
    "            # Initialize dictionaries to hold the visitor and home team data\n",
    "            visitor_data = {'event_date':event_date,'team': visitor_team}\n",
    "            home_data = {'event_date':event_date,'team': home_team}\n",
    "            \n",
    "            # Loop through the rows to extract each stat\n",
    "            for row in rows[1:]:  # Skipping the first row as it's the column headers\n",
    "                stat_name = row.find('th').text.strip()\n",
    "                vis_stat = row.find_all('td')[0].text.strip()\n",
    "                home_stat = row.find_all('td')[1].text.strip()\n",
    "                \n",
    "                # Handle different stat formats (Rush-Yds-TDs, Cmp-Att-Yd-TD-INT, etc.)\n",
    "                if stat_name == \"Rush-Yds-TDs\":\n",
    "                    vis_rush = vis_stat.replace('--', '-').split('-')\n",
    "                    home_rush = home_stat.replace('--', '-').split('-')\n",
    "                    visitor_data['rush_att'] = int(vis_rush[0])\n",
    "                    visitor_data['rush_yds'] = int(vis_rush[1])\n",
    "                    visitor_data['rush_tds'] = int(vis_rush[2])\n",
    "                    home_data['rush_att'] = int(home_rush[0])\n",
    "                    home_data['rush_yds'] = int(home_rush[1])\n",
    "                    home_data['rush_tds'] = int(home_rush[2])\n",
    "                \n",
    "                elif stat_name == \"Cmp-Att-Yd-TD-INT\":\n",
    "                    vis_pass = vis_stat.replace('--', '-').split('-')\n",
    "                    home_pass = home_stat.replace('--', '-').split('-')\n",
    "                    visitor_data['pass_cmp'] = int(vis_pass[0])\n",
    "                    visitor_data['pass_att'] = int(vis_pass[1])\n",
    "                    try:\n",
    "                        visitor_data[\"pass_cmp_pct\"] = round((visitor_data['pass_cmp'] / visitor_data['pass_att']), 3)\n",
    "                    except ZeroDivisionError:\n",
    "                        visitor_data[\"pass_cmp_pct\"] = 0\n",
    "                    visitor_data['pass_yds'] = int(vis_pass[2])\n",
    "                    visitor_data['pass_tds'] = int(vis_pass[3])\n",
    "                    visitor_data['pass_int'] = int(vis_pass[4])\n",
    "                    home_data['pass_cmp'] = int(home_pass[0])\n",
    "                    home_data['pass_att'] = int(home_pass[1])\n",
    "                    try:\n",
    "                        home_data[\"pass_cmp_pct\"] = round((home_data['pass_cmp'] / home_data['pass_att']), 3)\n",
    "                    except ZeroDivisionError:\n",
    "                        home_data[\"pass_cmp_pct\"] = 0\n",
    "                    home_data['pass_yds'] = int(home_pass[2])\n",
    "                    home_data['pass_tds'] = int(home_pass[3])\n",
    "                    home_data['pass_int'] = int(home_pass[4])\n",
    "\n",
    "                elif stat_name == \"Sacked-Yards\":\n",
    "                    vis_sacked = vis_stat.split('-')\n",
    "                    home_sacked = home_stat.split('-')\n",
    "                    visitor_data['times_sacked'] = int(vis_sacked[0])\n",
    "                    visitor_data['yds_sacked_for'] = int(vis_sacked[1])\n",
    "                    home_data['times_sacked'] = int(home_sacked[0])\n",
    "                    home_data['yds_sacked_for'] = int(home_sacked[1])\n",
    "\n",
    "                elif stat_name == \"Fumbles-Lost\":\n",
    "                    vis_fumble = vis_stat.split('-')\n",
    "                    home_fumble = home_stat.split('-')\n",
    "                    visitor_data['fumbles'] = int(vis_fumble[0])\n",
    "                    visitor_data['fumbles_lost'] = int(vis_fumble[1])\n",
    "                    home_data['fumbles'] = int(home_fumble[0])\n",
    "                    home_data['fumbles_lost'] = int(home_fumble[1])\n",
    "\n",
    "                elif stat_name == \"Penalties-Yards\":\n",
    "                    vis_penalties = vis_stat.split('-')\n",
    "                    home_penalties = home_stat.split('-')\n",
    "                    visitor_data['penalties'] = int(vis_penalties[0])\n",
    "                    visitor_data['penalty_yds'] = int(vis_penalties[1])\n",
    "                    home_data['penalties'] = int(home_penalties[0])\n",
    "                    home_data['penalty_yds'] = int(home_penalties[1])\n",
    "\n",
    "                elif stat_name == \"Third Down Conv.\":\n",
    "                    vis_third_down = vis_stat.split('-')\n",
    "                    home_third_down = home_stat.split('-')\n",
    "                    visitor_data['third_down_conv'] = int(vis_third_down[0])\n",
    "                    visitor_data['third_down_att'] = int(vis_third_down[1])\n",
    "                    try:\n",
    "                        visitor_data['third_down_conv_pct'] = round((visitor_data['third_down_conv']/visitor_data['third_down_att']),3)\n",
    "                    except ZeroDivisionError:\n",
    "                        visitor_data['third_down_conv_pct'] = 0                \n",
    "                    home_data['third_down_conv'] = int(home_third_down[0])\n",
    "                    home_data['third_down_att'] = int(home_third_down[1])\n",
    "                    try:\n",
    "                        home_data['third_down_conv_pct'] = round((home_data['third_down_conv']/home_data['third_down_att']),3)\n",
    "                    except ZeroDivisionError:\n",
    "                        home_data['third_down_conv_pct'] = 0                \n",
    "\n",
    "                elif stat_name == \"Fourth Down Conv.\":\n",
    "                    vis_fourth_down = vis_stat.split('-')\n",
    "                    home_fourth_down = home_stat.split('-')\n",
    "                    visitor_data['fourth_down_conv'] = int(vis_fourth_down[0])\n",
    "                    visitor_data['fourth_down_att'] = int(vis_fourth_down[1])\n",
    "                    try:\n",
    "                        visitor_data['fourth_down_conv_pct'] = round((visitor_data['fourth_down_conv']/visitor_data['fourth_down_att']),3)\n",
    "                    except ZeroDivisionError:\n",
    "                        visitor_data['fourth_down_conv_pct'] = 0\n",
    "                    home_data['fourth_down_conv'] = int(home_fourth_down[0])\n",
    "                    home_data['fourth_down_att'] = int(home_fourth_down[1])\n",
    "                    try:\n",
    "                        home_data['fourth_down_conv_pct'] = round((home_data['fourth_down_conv']/home_data['fourth_down_att']),3)\n",
    "                    except ZeroDivisionError:\n",
    "                        home_data['fourth_down_conv_pct'] = 0\n",
    "                \n",
    "                elif stat_name == \"Time of Possession\":\n",
    "                    vis_pos_time = vis_stat.split(':')\n",
    "                    home_pos_time = home_stat.split(':')\n",
    "                    visitor_data['time_of_possession'] = (int(vis_pos_time[0])*60) + int(vis_pos_time[1])\n",
    "                    home_data['time_of_possession'] = (int(home_pos_time[0])*60) + int(home_pos_time[1])\n",
    "\n",
    "                else:\n",
    "                    # Other stats like Net Pass Yards, Total Yards, Turnovers, etc.\n",
    "                    visitor_data[stat_name.replace(' ', '_').lower()] = vis_stat\n",
    "                    home_data[stat_name.replace(' ', '_').lower()] = home_stat\n",
    "            \n",
    "            # Add the extracted data to the main data list\n",
    "            data.append(visitor_data)\n",
    "            data.append(home_data)\n",
    "\n",
    "    # Convert the extracted data into a Pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## games info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def games_info(boxscore_link):\n",
    "    \"\"\"\n",
    "    Fetch game-related information and extract statistics.\n",
    "\n",
    "    Parameters:\n",
    "    boxscore_link (str): URL to the game's boxscore page.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing game information dictionary, team stats DataFrame, starters DataFrame, \n",
    "           snap counts DataFrame, and DataFrames for various player statistics (offense, defense, returns, kicking, etc.).\n",
    "    \"\"\"\n",
    "    # return game info dict\n",
    "    page = requests.get(boxscore_link)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    comments = soup.find_all(string = lambda text: isinstance(text, Comment))\n",
    "\n",
    "    coach_tag = soup.find_all('div', class_='datapoint')\n",
    "    coaches = [coach.find('a').text for coach in coach_tag]\n",
    "    team_tag = soup.find_all('div', class_='scorebox')\n",
    "    teams = [t.text for tm in team_tag[0].find_all('strong') if (t := tm.find('a')) is not None]\n",
    "    coach_team = dict(zip(teams, coaches))\n",
    "\n",
    "    event_date=date_func(boxscore_link)\n",
    "\n",
    "    #individual game data\n",
    "    i_team_stats = team_stats(comments,event_date)\n",
    "\n",
    "    i_starters = game_starters(comments,event_date)\n",
    "\n",
    "    i_snap_counts = snap_counts(comments,event_date)\n",
    "\n",
    "    i_player_offense = player_offense(soup,event_date)\n",
    "\n",
    "    i_player_defense = player_defense(comments,event_date)\n",
    "\n",
    "    i_player_returns = player_returns(comments,event_date)\n",
    "\n",
    "    i_player_kicking = player_kicking(comments,event_date)\n",
    "\n",
    "    i_player_advance_passing = player_advanced_passing(comments,event_date)\n",
    "\n",
    "    i_player_advance_rushing = player_advanced_rushing(comments,event_date)\n",
    "\n",
    "    i_player_advance_receiving = player_advanced_receiving(comments,event_date)\n",
    "\n",
    "    i_player_advance_defense = player_advanced_defense(comments,event_date)\n",
    "\n",
    "\n",
    "    game_info = {\n",
    "        'won_toss': None,\n",
    "        'won_toss_decision': None,\n",
    "        'won_toss_overtime': None,\n",
    "        'won_toss_overtime_decision': None,\n",
    "        'attendance': None,\n",
    "        'duration': None,\n",
    "        'roof_type': None,\n",
    "        'surface_type': None,\n",
    "        'temperature': None,\n",
    "        'humidity_pct': None,\n",
    "        'wind_speed': None,\n",
    "        'team_spread': None,\n",
    "        'over_under': None,\n",
    "        'coaches':coach_team\n",
    "    }\n",
    "\n",
    "    # Extract relevant data from the comments\n",
    "    for comment in comments:\n",
    "        if 'id=\"game_info\"' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            table = comment_soup.find('table')\n",
    "            if table:\n",
    "                rows = table.find_all('tr')\n",
    "                \n",
    "                for row in rows:\n",
    "                    header = row.find('th').text.strip() if row.find('th') else None\n",
    "                    value = row.find('td').text.strip() if row.find('td') else None\n",
    "\n",
    "                    # Map the data from the table to the appropriate field\n",
    "                    if header == \"Won Toss\":\n",
    "                        won_toss_text = value\n",
    "                        if 'deferred' in won_toss_text:\n",
    "                            game_info['won_toss'] = won_toss_text.split()[0]\n",
    "                            game_info['won_toss_decision'] = 'deferred'\n",
    "                        else:\n",
    "                            game_info['won_toss'] = won_toss_text\n",
    "                            game_info['won_toss_decision'] = 'accepted'\n",
    "                    elif header == \"Won OT Toss\":\n",
    "                        won_ot_toss_text = value\n",
    "                        if 'deferred' in won_ot_toss_text:\n",
    "                            game_info['won_toss_overtime'] = won_toss_text.split()[0]\n",
    "                            game_info['won_toss_overtime_decision'] = 'deferred'\n",
    "                        else:\n",
    "                            game_info['won_toss_overtime'] = won_ot_toss_text\n",
    "                            game_info['won_toss_overtime_decision'] = 'accepted'\n",
    "                    elif header == \"Roof\":\n",
    "                        game_info['roof_type'] = value\n",
    "                    elif header == \"Surface\":\n",
    "                        game_info['surface_type'] = value\n",
    "                    elif header == \"Duration\":\n",
    "                        game_info['duration'] = int(value.split(\":\")[0]) * 60 + int(value.split(\":\")[1])\n",
    "                    elif header == \"Attendance\":\n",
    "                        game_info['attendance'] = int(value.replace(\",\", \"\"))\n",
    "                    elif header == \"Weather\":\n",
    "                        game_info['temperature'], game_info['humidity_pct'], game_info['wind_speed'] = parse_weather(value)\n",
    "                    elif header == \"Vegas Line\":\n",
    "                        game_info['team_spread'] = value  # Extract the team spread\n",
    "                    elif header == \"Over/Under\":\n",
    "                        game_info['over_under'] = value  # Extract the over/under total\n",
    "    return game_info, i_team_stats, i_starters, i_snap_counts, i_player_offense, i_player_defense, i_player_returns, i_player_kicking, i_player_advance_passing, i_player_advance_rushing, i_player_advance_receiving, i_player_advance_defense\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_game_data(url,year):\n",
    "    \"\"\"\n",
    "    Scrape game data for a specific year from the given URL.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): URL of the page containing game information for the specified year.\n",
    "    year (int): The year for which game data is being scraped.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the games DataFrame and a list of DataFrames for team stats, \n",
    "           starters, snap counts, and various player statistics.\n",
    "    \"\"\"\n",
    "    # Fetch the page content\n",
    "    season = year\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    # Find all the rows in the table\n",
    "    rows = soup.find_all('tr')\n",
    "\n",
    "    # Data to be extracted\n",
    "    games_data = []\n",
    "\n",
    "    # Initialize empty lists to store DataFrames\n",
    "    team_stats_list = []\n",
    "    starters_list =[]\n",
    "    snap_counts_list = []\n",
    "    player_offense_list = []\n",
    "    player_defense_list = [] \n",
    "    player_returns_list = [] \n",
    "    player_kicking_list = [] \n",
    "    player_advance_passing_list = [] \n",
    "    player_advance_rushing_list = [] \n",
    "    player_advance_receiving_list = []\n",
    "    player_advance_defense_list = []\n",
    "\n",
    "\n",
    "    for row in rows:\n",
    "        # Extract each field (skip rows without enough columns)\n",
    "        columns = row.find_all('td')\n",
    "\n",
    "        week = row.find_all('th')[0].text.strip()\n",
    "        if len(columns) < 13 or columns[1].text.strip() == 'Playoffs':\n",
    "            continue\n",
    "        \n",
    "        # Extract required data\n",
    "        week_day = columns[0].text.strip()\n",
    "        event_date = columns[1].text.strip()\n",
    "        game_time = columns[2].text.strip()\n",
    "        team_a = columns[3].text.strip()\n",
    "        team_b = columns[5].text.strip()\n",
    "        game_location = columns[4].text.strip()\n",
    "\n",
    "        try:\n",
    "            # Logic to determine game location\n",
    "            if game_location == '@':\n",
    "                location = \" \".join(team_b.split()[:-1])\n",
    "            elif game_location == 'N':\n",
    "                location = \"Niether\"\n",
    "            else:\n",
    "                location = \" \".join(team_a.split()[:-1])\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        team_a_score = columns[7].text.strip()\n",
    "        team_b_score = columns[8].text.strip()\n",
    "        team_a_yards = columns[9].text.strip()\n",
    "        team_a_turnover = columns[10].text.strip()\n",
    "        team_b_yards = columns[11].text.strip()\n",
    "        team_b_turnover = columns[12].text.strip()\n",
    "        \n",
    "        boxscore_link = columns[6].find('a')['href'] if columns[6].find('a') else ''\n",
    "        boxscore_link = f\"https://www.pro-football-reference.com{boxscore_link}\"  # Complete the URL\n",
    "\n",
    "        i_gi, i_ts, i_s, i_sc, i_po, i_pd, i_pr, i_pk, i_pap, i_paru, i_parc, i_pad = games_info(boxscore_link)\n",
    "        team_stats_list.append(i_ts)\n",
    "        starters_list.append(i_s)\n",
    "        snap_counts_list.append(i_sc)\n",
    "        player_offense_list.append(i_po)\n",
    "        player_defense_list.append(i_pd)\n",
    "        player_returns_list.append(i_pr)\n",
    "        player_kicking_list.append(i_pk)\n",
    "        player_advance_passing_list.append(i_pap)\n",
    "        player_advance_rushing_list.append(i_paru)\n",
    "        player_advance_receiving_list.append(i_parc)\n",
    "        player_advance_defense_list.append(i_pad)\n",
    "        \n",
    "        # Append to list of games\n",
    "        games_data.append({**{\n",
    "            'season':season,\n",
    "            'week': week,\n",
    "            'week_day': week_day,\n",
    "            'event_date': event_date,\n",
    "            'game_time': game_time,\n",
    "            'team_a': team_a,\n",
    "            'team_b': team_b,\n",
    "            'location': location,\n",
    "            'team_a_score': team_a_score,\n",
    "            'team_b_score': team_b_score,\n",
    "            'team_a_yards': team_a_yards,\n",
    "            'team_a_turnover': team_a_turnover,\n",
    "            'team_b_yards': team_b_yards,\n",
    "            'team_b_turnover': team_b_turnover,\n",
    "            'boxscore_link': boxscore_link\n",
    "        }, **i_gi})\n",
    "\n",
    "        # Sleep for a random time between 3.5 to 5.5 seconds to avoid overwhelming the server\n",
    "        time.sleep(random.uniform(3.5, 5.5))\n",
    "\n",
    "    # Convert the data into a DataFrame\n",
    "    df_games = pd.DataFrame(games_data)\n",
    "\n",
    "    return df_games, team_stats_list, starters_list, snap_counts_list, player_offense_list, player_defense_list, player_returns_list, player_kicking_list, player_advance_passing_list, player_advance_rushing_list, player_advance_receiving_list, player_advance_defense_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scrap and combine func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_combine_data(years, folder_path):\n",
    "    \"\"\"\n",
    "    Scrape data for the specified years and save combined data for each type as CSV files.\n",
    "\n",
    "    Parameters:\n",
    "    years (list of int): List of years to scrape data for.\n",
    "    folder_path (str): Directory path to save the combined CSV files.\n",
    "    \"\"\" \n",
    "    # Initialize dictionaries to store lists of DataFrames for each type\n",
    "    combined_dataframes = {\n",
    "        'y_g': [],\n",
    "        'y_ts': [],\n",
    "        'y_st': [],\n",
    "        'y_sn': [],\n",
    "        'y_po': [],\n",
    "        'y_pd': [],\n",
    "        'y_pr': [],\n",
    "        'y_pk': [],\n",
    "        'y_pap': [],\n",
    "        'y_paru': [],\n",
    "        'y_parc': [],\n",
    "        'y_pad': []\n",
    "    }\n",
    "\n",
    "    # Loop over each year and scrape the data\n",
    "    for year in years:\n",
    "        url = f\"https://www.pro-football-reference.com/years/{year}/games.htm\"\n",
    "        \n",
    "        # Scrape the data for the given year\n",
    "        y_g, y_ts, y_st, y_sn, y_po, y_pd, y_pr, y_pk, y_pap, y_paru, y_parc, y_pad = scrape_game_data(url, year)\n",
    "        \n",
    "        # Append the data to the corresponding lists in combined_dataframes\n",
    "        combined_dataframes['y_g'].append(y_g)\n",
    "        combined_dataframes['y_ts'].extend(y_ts)  # Extend since these are lists of DataFrames\n",
    "        combined_dataframes['y_st'].extend(y_st)\n",
    "        combined_dataframes['y_sn'].extend(y_sn)\n",
    "        combined_dataframes['y_po'].extend(y_po)\n",
    "        combined_dataframes['y_pd'].extend(y_pd)\n",
    "        combined_dataframes['y_pr'].extend(y_pr)\n",
    "        combined_dataframes['y_pk'].extend(y_pk)\n",
    "        combined_dataframes['y_pap'].extend(y_pap)\n",
    "        combined_dataframes['y_paru'].extend(y_paru)\n",
    "        combined_dataframes['y_parc'].extend(y_parc)\n",
    "        combined_dataframes['y_pad'].extend(y_pad)\n",
    "\n",
    "        print(f\"Scraped data for year {year}\")\n",
    "\n",
    "        # Sleep for a random time between 3.5 to 5.5 seconds to avoid overwhelming the server\n",
    "        time.sleep(random.uniform(3.5, 5.5))\n",
    "\n",
    "    # Combine and save each type of DataFrame to a single file\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Dictionary mapping DataFrame names (as strings) to their respective filenames\n",
    "    dataframe_filenames = {\n",
    "        'y_g': \"games_info_all.csv\",\n",
    "        'y_ts': \"team_stats_all.csv\",\n",
    "        'y_st': \"starters_all.csv\",\n",
    "        'y_sn': \"snap_counts_all.csv\",\n",
    "        'y_po': \"player_offense_all.csv\",\n",
    "        'y_pd': \"player_defense_all.csv\",\n",
    "        'y_pr': \"player_returns_all.csv\",\n",
    "        'y_pk': \"player_kicking_all.csv\",\n",
    "        'y_pap': \"player_ad_pass_all.csv\",\n",
    "        'y_paru': \"player_ad_rush_all.csv\",\n",
    "        'y_parc': \"player_ad_recv_all.csv\",\n",
    "        'y_pad': \"player_ad_dfns_all.csv\"\n",
    "    }\n",
    "\n",
    "    # Combine and save each DataFrame\n",
    "    for df_name, filename in dataframe_filenames.items():\n",
    "        # Concatenate all the DataFrames in the list for the given type\n",
    "        combined_df = pd.concat(combined_dataframes[df_name], ignore_index=True)\n",
    "        \n",
    "        # Create the full file path\n",
    "        csv_filename = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Save the combined DataFrame to a single CSV file\n",
    "        combined_df.to_csv(csv_filename, index=False)\n",
    "        print(f\"Saved combined data to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scrap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder where you want to save the CSV files\n",
    "folder_path = \"../data\"  # Update this to your desired directory\n",
    "\n",
    "# Ensure the folder exists\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# # Define the years you want to scrape data for\n",
    "# years = list(range(2022, 2024))\n",
    "\n",
    "# # Call the function to scrape and save the data\n",
    "# scrape_and_combine_data(years, folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
